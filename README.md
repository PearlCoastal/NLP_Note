#  Natural Language Processing
Basic acknowledge of natural language processing models.

1. Attention Mechanism
2. Difference between attention and self-attention.
3. How self-attention worked.
4. About multi-head self-attention.
5. Some classifier function: Sigmoid, Softmax, Tanh and ReLu.
6. Little about CNN and RNN.
7. How transformer solved long-distance dependency problem.
8. Descrption of transformer models.


ðŸ‘‰ [Note](https://github.com/PearlCoastal/NLP_Note/blob/master/AttentionMechanism.md)

# Machine Learning Note

About logistic regression and linear regression.

ðŸ‘‰[Note](https://github.com/PearlCoastal/NLP_Note/blob/master/%E5%88%86%E7%B1%BB%E7%AE%97%E6%B3%95.md)
