# NLP_Note
Basic acknowledge of natural language processing models.

1. Attention Mechanism
2. Difference between attention and self-attention.
3. How self-attention worked.
4. About multi-head self-attention.
5. Some classifier function: Sigmoid, Softmax, Tanh and ReLu.
6. Little about CNN and RNN.
7. How transformer solved long-distance dependency problem.
8. Descrption of transformer models.

